data_list2 <- list()
for (i in 1:length(A)){
pNumber = A[i]
wd1 <-  paste("//cnas.ru.nl/wrkgrp/STD-Back-Up-Exp2-EEG/", pNumber,"/Day3/",pNumber,"_FinalTest", sep="")
wd2 <-  paste("//cnas.ru.nl/wrkgrp/STD-Back-Up-Exp2-EEG/", pNumber,"/Day2/",pNumber,"_Posttest_Day2", sep="")
wd3 <- paste("//cnas.ru.nl/wrkgrp/STD-Back-Up-Exp2-EEG/", pNumber,"/Day3/",pNumber,"_Familiarization", sep="")
wd4 <- paste("//cnas.ru.nl/wrkgrp/STD-Back-Up-Exp2-EEG/", pNumber,"/Day1/", sep="")
infile1 <- paste(pNumber,"Posttest_Day2.txt",sep="_")
infile2 <- paste(pNumber,"Finaltest.txt",sep="_")
infile3 <- paste(pNumber, "IntFamiliarization.txt", sep="_")
infile4 <- paste(pNumber, "Familiarization_Day1.txt", sep="_")
behav <- matrix(NA,140,9)
setwd(wd2)
currentFile <- as.data.frame(read.delim(infile1, stringsAsFactors=FALSE, sep = "\t", header = T, skipNul = TRUE))
#as.numeric(gsub(",",".", currentFile$RT_new))
if (length(currentFile[currentFile$Error == 999,]$Error) > 0){
currentFile[currentFile$Error == 999,]$Error<-1
}
data_list[[i]] <- currentFile
setwd(wd1)
currentFile2 <- as.data.frame(read.delim(infile2, stringsAsFactors=FALSE, sep = "\t", header = T, skipNul = TRUE))
# inititate a column for the median split by RTs later
currentFile2$RTsSplit <- currentFile2$RT_new
## marking unlearned words as missing values in posttest ##
for (j in 1:nrow(currentFile)) {
pos <- which(tolower(as.character(currentFile2$Item )) == tolower(as.character(currentFile$Item[j])))
behav[pos,1] <- currentFile2$Trial_nr[pos]
behav[pos,2]<- currentFile2$Condition[pos]
behav[pos,3]<- currentFile2$VoiceOnset[pos]
behav[pos,4]<- currentFile2$TypeError[pos]
if (currentFile$Error[j] == 1) {
currentFile2$Error[pos] <- NA
currentFile2$VoiceOnset[pos] <- NA
currentFile2$RT_new[pos] <- NA
currentFile2$PhonCorrect[pos]<- NA
currentFile2$PhonIncorrect[pos]<-NA
currentFile2$RTsSplit[pos] <- NA
behav[pos,5]<- 1
behav[pos,9]<- 0} else {
behav[pos,5]<- 0
behav[pos,9]<- 1
}
}
if (length(currentFile2[ifelse(is.na(currentFile2$Error),
1,currentFile2$Error) == 999,]$Error) > 0) {
currentFile2[ifelse(is.na(currentFile2$Error),
1,currentFile2$Error) == 999,]$Error<-1
}
if (length(currentFile2[ifelse(is.na(currentFile2$Error),
0,currentFile2$Error) == 1,]$VoiceOnset) > 0) {
currentFile2[ifelse(is.na(currentFile2$Error),
0,currentFile2$Error) == 1,]$VoiceOnset <- NA # this excludes words that were produced with errors after interference from RT analysis
}
if (length(currentFile2[ifelse(is.na(currentFile2$Error),
0,currentFile2$Error) == 1,]$RT_new) > 0) {
currentFile2[ifelse(is.na(currentFile2$Error),
0,currentFile2$Error) == 1,]$RT_new <- NA # this excludes words that were produced with errors after interference from RT analysis
}
if (length(currentFile2[ifelse(is.na(currentFile2$Error),
0,currentFile2$Error) == 1,]$RTsSplit) > 0) {
currentFile2[ifelse(is.na(currentFile2$Error),
0,currentFile2$Error) == 1,]$RTsSplit <- 100000 # this marks words that were produced with errors after interference from RT analysis
}
## exlcude items that were unknown in English
setwd(wd3)
currentFile3 <- as.data.frame(read.delim(infile3, stringsAsFactors=FALSE, sep = "\t", header = T, skipNul = TRUE))
for (j in 1:nrow(currentFile3)) {
pos <- which(tolower(as.character(currentFile2$Item )) == tolower(as.character(currentFile3$Item[j])))
if (currentFile3$Error[j] == 1) {
currentFile2$Error[pos] <- NA
currentFile2$VoiceOnset[pos] <- NA
currentFile2$RT_new[pos] <- NA
currentFile2$PhonCorrect[pos]<- NA
currentFile2$PhonIncorrect[pos]<-NA
currentFile2$RTsSplit[pos] <- NA
behav[pos,6]<-1
behav[pos,9]<- 0} else{
behav[pos,6]<-0}
}
# exclude words that were already known in Italian before the experiment
setwd(wd4)
currentFile4 <- as.data.frame(read.delim(infile4, stringsAsFactors=FALSE, sep = "\t", header = T, skipNul = TRUE))
for (j in 1:nrow(currentFile4)) {
pos <- which(tolower(as.character(currentFile2$Item )) == tolower(as.character(currentFile4$Item[j])))
if (currentFile4$Known[j] == 1) {
currentFile2$Error[pos] <- NA
currentFile2$VoiceOnset[pos] <- NA
currentFile2$RT_new[pos] <- NA
currentFile2$PhonCorrect[pos]<- NA
currentFile2$PhonIncorrect[pos]<-NA
currentFile2$RTsSplit[pos] <- NA
behav[pos,7]<-1
behav[pos,9]<- 0} else{
behav[pos,7]<-0}
}
data_list2[[i]] <- currentFile2
for (l in 1:nrow(currentFile2)) {
if (currentFile2$Error[l] == 1 || is.na(currentFile2$Error[l])) {
currentFile2$ReadIn[l] <- 0
behav[l,8]<-0
} else {
currentFile2$ReadIn[l] <- 1
behav[l,8]<-1
}
}
for (l in 1:nrow(behav)) {
if (is.na(behav[l,6]) == T) {
behav[l,6] <- 0
}
}
# calculate a mdedian per person based on RTs
currentFile2$MedianGroup_1 <- NA
currentFile2$MedianGroup_2 <- NA
currentFile2$MedianGroup_av <- NA
for (i in 1:70){
currentFile2$RTsSplitav[i] <- mean(c(currentFile2$RTsSplit[i], currentFile2$RTsSplit[i+70]))
currentFile2$RTsSplitav[i+70] <- mean(c(currentFile2$RTsSplit[i], currentFile2$RTsSplit[i+70]))
}
med1 = median(currentFile2[currentFile2$Trial_nr<71 & currentFile2$Condition==1,]$RTsSplit, na.rm = T)
med2 = median(currentFile2[currentFile2$Trial_nr>70 & currentFile2$Condition==1,]$RTsSplit, na.rm = T)
med3 = median(currentFile2[currentFile2$Trial_nr<71 & currentFile2$Condition==1,]$RTsSplitav, na.rm = T)
for (l in 1:nrow(currentFile2[currentFile2$Trial_nr<71,])) {
if (nrow(currentFile2[is.na(currentFile2[currentFile2$Trial_nr<71,]$RTsSplit) == 0 & currentFile2[currentFile2$Trial_nr<71,]$RTsSplit > med1,]) > 35){
if (is.na(currentFile2[currentFile2$Trial_nr<71,]$RTsSplit[l]) == 0 & currentFile2[currentFile2$Trial_nr<71,]$RTsSplit[l] <= med1 ) {
currentFile2$MedianGroup_1[l] <- 1
currentFile2$MedianGroup_1[l+70] <- 1
} else if (is.na(currentFile2[currentFile2$Trial_nr<71,]$RTsSplit[l]) == 0 & currentFile2[currentFile2$Trial_nr<71,]$RTsSplit[l] > med1) {
currentFile2$MedianGroup_1[l] <- 2
currentFile2$MedianGroup_1[l+70] <- 2
}
}
else {
if (is.na(currentFile2[currentFile2$Trial_nr<71,]$RTsSplit[l]) == 0 & currentFile2[currentFile2$Trial_nr<71,]$RTsSplit[l] < med1 ) {
currentFile2$MedianGroup_1[l] <- 1
currentFile2$MedianGroup_1[l+70] <- 1
} else if (is.na(currentFile2[currentFile2$Trial_nr<71,]$RTsSplit[l]) == 0 & currentFile2[currentFile2$Trial_nr<71,]$RTsSplit[l] >= med1) {
currentFile2$MedianGroup_1[l] <- 2
currentFile2$MedianGroup_1[l+70] <- 2
}}
}
for (l in 71:140) {
if (nrow(currentFile2[is.na(currentFile2[currentFile2$Trial_nr>70,]$RTsSplit) == 0 & currentFile2[currentFile2$Trial_nr>70,]$RTsSplit > med2,]) > 35){
if (is.na(currentFile2$RTsSplit[l]) == 0 & currentFile2$RTsSplit[l] <= med2 ) {
currentFile2$MedianGroup_2[l] <- 1
currentFile2$MedianGroup_2[l-70] <- 1
} else if (is.na(currentFile2$RTsSplit[l]) == 0 & currentFile2$RTsSplit[l] > med2) {
currentFile2$MedianGroup_2[l] <- 2
currentFile2$MedianGroup_2[l-70] <- 2
}
}
else {
if (is.na(currentFile2$RTsSplit[l]) == 0 & currentFile2$RTsSplit[l] < med2 ) {
currentFile2$MedianGroup_2[l] <- 1
currentFile2$MedianGroup_2[l-70] <- 1
} else if (is.na(currentFile2$RTsSplit[l]) == 0 & currentFile2$RTsSplit[l] >= med2) {
currentFile2$MedianGroup_2[l] <- 2
currentFile2$MedianGroup_2[l-70] <- 2
}}
}
for (l in 1:nrow(currentFile2[currentFile2$Trial_nr<71,])) {
if (nrow(currentFile2[is.na(currentFile2[currentFile2$Trial_nr<71,]$RTsSplitav) == 0 & currentFile2[currentFile2$Trial_nr<71,]$RTsSplitav > med3,]) > 35){
if (is.na(currentFile2[currentFile2$Trial_nr<71,]$RTsSplitav[l]) == 0 & currentFile2[currentFile2$Trial_nr<71,]$RTsSplitav[l] <= med3 ) {
currentFile2$MedianGroup_av[l] <- 1
currentFile2$MedianGroup_av[l+70] <- 1
} else if (is.na(currentFile2[currentFile2$Trial_nr<71,]$RTsSplitav[l]) == 0 & currentFile2[currentFile2$Trial_nr<71,]$RTsSplitav[l] > med3) {
currentFile2$MedianGroup_av[l] <- 2
currentFile2$MedianGroup_av[l+70] <- 2
}
}
else {
if (is.na(currentFile2[currentFile2$Trial_nr<71,]$RTsSplitav[l]) == 0 & currentFile2[currentFile2$Trial_nr<71,]$RTsSplitav[l] < med3 ) {
currentFile2$MedianGroup_av[l] <- 1
currentFile2$MedianGroup_av[l+70] <- 1
} else if (is.na(currentFile2[currentFile2$Trial_nr<71,]$RTsSplitav[l]) == 0 & currentFile2[currentFile2$Trial_nr<71,]$RTsSplitav[l] >= med3) {
currentFile2$MedianGroup_av[l] <- 2
currentFile2$MedianGroup_av[l+70] <- 2
}}
}
# safe the new Final test file for the NewMarker.m script
setwd(wd1)
outfile = paste(pNumber,"Finaltest_new.txt",sep="_")
write.table(currentFile2, outfile, quote = F, row.names = F, col.names = T, sep = "\t")
# safe the file with the relevant behavioral information as text (for preprocessing script)
# columns as follows: TrialNr, Condition, VoiceOnset, TypeError, Not learned in Spanish, unknown in English, known in Italian, Read in
#setwd(wd1)
#outfile2 = paste(pNumber,"BehavMatrixFinalTest.txt",sep="_")
#write.table(behav, outfile2, quote = F, row.names = F, col.names = F, sep = "\t")
print("###")
print(pNumber)
print(nrow(currentFile2[is.na(currentFile2$MedianGroup_1) == 0 & currentFile2$Condition ==1 & currentFile2$Trial_nr<71 & currentFile2$MedianGroup_1==1,]))
print(nrow(currentFile2[is.na(currentFile2$MedianGroup_1) == 0 & currentFile2$Condition ==1 & currentFile2$Trial_nr<71 & currentFile2$MedianGroup_1==2,]))
print(nrow(currentFile2[is.na(currentFile2$MedianGroup_2) == 0 & currentFile2$Condition ==1 & currentFile2$Trial_nr>70 & currentFile2$MedianGroup_2==1,]))
print(nrow(currentFile2[is.na(currentFile2$MedianGroup_2) == 0 & currentFile2$Condition ==1 & currentFile2$Trial_nr>70 & currentFile2$MedianGroup_2==2,]))
print(nrow(currentFile2[is.na(currentFile2$MedianGroup_av) == 0 & currentFile2$Condition ==1 & currentFile2$Trial_nr<71 & currentFile2$MedianGroup_av==1,]))
print(nrow(currentFile2[is.na(currentFile2$MedianGroup_av) == 0 & currentFile2$Condition ==1 & currentFile2$Trial_nr<71 & currentFile2$MedianGroup_av==2,]))
print("###")
}
pre <- rbindlist(data_list)
post <- rbindlist(data_list2)
post$Subject_nr <- as.factor(post$Subject_nr)
post$Condition <- as.factor(post$Condition)
post$Item <- as.factor(post$Item)
post$Block <- as.factor(post$Block)
# leaving out RTs under 2000ms
post[post$RT_new < 2000,]$RT_new <- NA
# log-transforming the NEW and OLD RTs
post$RTlog <- log(post$VoiceOnset-2000)
post$RT_new_log <- log(post$RT_new-2000)
# calculating ratio
post$Total <- post$PhonCorr+post$PhonIncorr
post$Ratio <- (post$PhonCorr/post$Total)*100
# subset to only the first round of Final test
post1 <- post[post$Trial_nr<71,]
post2 <- post[post$Trial_nr>70,]
########## Plots with GGplot ###########
require(plyr)
require(ggplot2)
require(lme4)
require(lmerTest)
require(lmtest)
setwd("//cnas.ru.nl/wrkgrp/STD-Back-Up-Exp2-EEG/")
lenwords <- read.delim("WordsLengths.txt")
post$OrigLen <- NA
for (j in 1:nrow(post)) {
pos <- which(tolower(as.character(lenwords$English)) == tolower(as.character(post$Item[j])))
post$OrigLen[j] <- lenwords[pos,3] #}
print(j)
rm(pos)
}
post$CorrPer <- round(post$PhonCorrect/post$Total,2)
post$Corr <- round(post$CorrPer*post$OrigLen,0)
#post$Corr <- round(post$CorrPer*post$PhonCorrect,0)
post$Incorr <- post$OrigLen-post$Corr
# setting contrasts to the mean of each condition
contrasts(post$Condition) <- c(0.5,-0.5)
contrasts(post$Block) <- c(-0.5,0.5)
# turning my factors into numerical factors reflecting a dummy coding
post$ConditionN <- (-(as.numeric(post$Condition)-2))-0.5
post$BlockN <- (as.numeric(post$Block)-1)-0.5
View(post)
## Full model with maximal random effects structure
modelfull <- glmer(cbind(Corr, Incorr) ~ ConditionN*BlockN + (1|Item) + (1+BlockN*ConditionN|Subject_nr), family = "binomial", control=glmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 100000)), data = post)
summary(modelfull)
## Full model on log transformed data
# Full model with maximum random effects structure
# We take the log of the reaction times because the distribution is very non-normal, and we subtract 2000ms because that's the lowest value there is currently (due to 2s delay), log transform works better if there are values close to 0 and between 0-1
modelRT2full <- lmer(log(RT_new-2000) ~ ConditionN*BlockN + (1|Item) + (1+BlockN*ConditionN|Subject_nr), control=lmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 100000)),data = post)
summary(modelRT2full)
# The chi-square p-value from the Anova table is the p-value for the main effect of Round/Block
# Finally, let's take out the interaction
modelRT2Interaction <- lmer(log(RT_new) ~ ConditionN*BlockN - ConditionN:BlockN + (1|Item) + (1+BlockN*ConditionN|Subject_nr), control=lmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 100000)),data = post)
anova(modelRT2full, modelRT2Interaction)
# The chi-square p-value from the Anova table is the p-value for the main effect of Round/Block
# Finally, let's take out the interaction
modelRT2Interaction <- lmer(log(RT_new) ~ ConditionN + BlockN + (1|Item) + (1+BlockN*ConditionN|Subject_nr), control=lmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 100000)),data = post)
anova(modelRT2full, modelRT2Interaction)
# The chi-square p-value from the Anova table is the p-value for the main effect of Round/Block
# Finally, let's take out the interaction
modelRT2Interaction <- lmer(log(RT_new-200) ~ ConditionN + BlockN + (1|Item) + (1+BlockN*ConditionN|Subject_nr), control=lmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 100000)),data = post)
anova(modelRT2full, modelRT2Interaction)
# The chi-square p-value from the Anova table is the p-value for the main effect of Round/Block
# Finally, let's take out the interaction
modelRT2Interaction <- lmer(log(RT_new-2000) ~ ConditionN + BlockN + (1|Item) + (1+BlockN*ConditionN|Subject_nr), control=lmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 100000)),data = post)
anova(modelRT2full, modelRT2Interaction)
### Seperate models for each round (just out of curiosity)
# Round 1
modelRT2round1 <- lmer(log(RT_new-2000) ~ ConditionN + (1|Item) + (1+ConditionN|Subject_nr), control=lmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 100000)),data = post[post$Block==1,])
summary(modelRT2round1)
# Round 2
modelRT2round2 <- lmer(log(RT_new-2000) ~ ConditionN + (1|Item) + (1+ConditionN|Subject_nr), control=lmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 100000)),data = post[post$Block==2,])
summary(modelRT2round2)
#### Adaptive learning task ####
# count number of exposure and learning success after the frist two rounds of this test
data_list <- list()
for (i in 1:length(A)){
pNumber = A[i]
wd1 <-  paste("//cnas.ru.nl/wrkgrp/STD-Back-Up-Exp2-EEG/", pNumber,"/Day2/",pNumber,"_AdapPicNaming", sep="")
setwd(wd1)
infile1 <- paste(pNumber,"AdapPicNamingDay2.txt",sep="_")
currentFile <- as.data.frame(read.delim(infile1, stringsAsFactors=FALSE, sep = "\t", header = T, skipNul = TRUE))
if (length(currentFile[currentFile$Error == 999,]$Error) > 0){
currentFile[currentFile$Error == 999,]$Error<-1
}
data_list[[i]] <- currentFile
print(A[i])
}
adap <- rbindlist(data_list)
blocks <- data.frame(tapply(adap$Block_nr, adap$Subject_nr,max)) # how many blocks did the pp go through
adaptive <- adap[adap$Block_nr <3,] # keep only the second block
adaptive <- adaptive[adaptive$Block_nr >1,]
successAdap <- 1-tapply(adaptive$Error, adaptive$Subject_nr,mean)
#### Exposure per item/pp ####
exposures<-data.frame(table(adap$Item, adap$Condition))
#exposures <- exposures[exposures$Freq != 0,]
exposures$Freq <- exposures$Freq + 12
exposures2<-data.frame(table(adap$Subject, adap$Condition))
exposures2[exposures2$Var2==2,]$Freq <- exposures2[exposures2$Var2==2,]$Freq +14
cond1 <- exposures2[exposures2$Var2==1,]$Freq
cond2 <- exposures2[exposures2$Var2==2,]$Freq
t.test(cond1,cond2)
reshape(exposures2, idvar = "Var1", timevar = "Var2", direction = "wide")
blocks
adaptive
successAdap
#### Exposure per item/pp ####
exposures<-data.frame(table(adap$Item, adap$Condition))
exposures
exposures3<-data.frame(table(adap$Item, adap$Subject_nr))
#exposures3 <- exposures3[exposures3$Freq != 0,]
exposures3$Freq <- exposures3$Freq + 12
expavg <- data.frame(tapply(exposures3$Freq, exposures3$Var2, mean))
expavg
exposures3
expavg <- data.frame(tapply(exposures3$Freq, exposures3$Var2, mean))
expavg
exposures3<-data.frame(table(adap$Item, adap$Subject_nr))
#exposures3 <- exposures3[exposures3$Freq != 0,]
exposures3$Freq <- exposures3$Freq + 12
expavg <- data.frame(tapply(exposures3$Freq, exposures3$Var2, mean))
mean(expavg)
mean(expavg$tapply.exposures3.Freq..exposures3.Var2..mean.)
sd(expavg$tapply.exposures3.Freq..exposures3.Var2..mean.)
min(expavg$tapply.exposures3.Freq..exposures3.Var2..mean.)
max(expavg$tapply.exposures3.Freq..exposures3.Var2..mean.)
min(exposures$Freq)
max(exposures$Freq)
max(exposures3$Freq)
min(exposures3$Freq)
### learning success at the end of Day 2 ###
data_list <- list()
for (i in 1:length(A)){
pNumber = A[i]
wd1 <-  paste("//cnas.ru.nl/wrkgrp/STD-Back-Up-Exp2-EEG/", pNumber,"/Day2/",pNumber,"_Posttest_Day2", sep="")
setwd(wd1)
infile1 <- paste(pNumber,"Postest_Day2.txt",sep="_")
currentFile <- as.data.frame(read.delim(infile1, stringsAsFactors=FALSE, sep = "\t", header = T, skipNul = TRUE))
if (length(currentFile[currentFile$Error == 999,]$Error) > 0){
currentFile[currentFile$Error == 999,]$Error<-1
}
data_list[[i]] <- currentFile
print(A[i])
}
for (i in 1:length(A)){
pNumber = A[i]
wd1 <-  paste("//cnas.ru.nl/wrkgrp/STD-Back-Up-Exp2-EEG/", pNumber,"/Day2/",pNumber,"_Posttest_Day2", sep="")
setwd(wd1)
infile1 <- paste(pNumber,"Posttest_Day2.txt",sep="_")
currentFile <- as.data.frame(read.delim(infile1, stringsAsFactors=FALSE, sep = "\t", header = T, skipNul = TRUE))
if (length(currentFile[currentFile$Error == 999,]$Error) > 0){
currentFile[currentFile$Error == 999,]$Error<-1
}
data_list[[i]] <- currentFile
print(A[i])
}
learn <- rbindlist(data_list)
m <- tapply(learn$Error, learn$Subject_nr)
m <- tapply(learn$Error, learn$Subject_nr, mean)
m
m <- 100-tapply(learn$Error, learn$Subject_nr, mean)
mean(m)
m
m <- 100-(tapply(learn$Error, learn$Subject_nr, mean)/70)
mean(m)
m
m <- 100-(tapply(learn$Error, learn$Subject_nr, sum)/70)
m
View(learn)
tapply(learn$Error, learn$Subject_nr, sum)
tapply(learn$Error, learn$Subject_nr, sum)/70
m <- 100-(tapply(learn$Error, learn$Subject_nr, sum)/70)*100
mean(m)
m
min(m)
0.8*70
### Familiarization Learning - Day 1 ####
# How many words were already known to people in Italian
data_list <- list()
for (i in 1:length(A)){
pNumber = A[i]
wd1 <-  paste("//cnas.ru.nl/wrkgrp/STD-Back-Up-Exp2-EEG/", pNumber,"/Day1/", sep="")
setwd(wd1)
infile1 <- paste(pNumber,"Familiarization_Day1.txt",sep="_")
currentFile <- as.data.frame(read.delim(infile1, stringsAsFactors=FALSE, sep = "\t", header = T, skipNul = TRUE))
data_list[[i]] <- currentFile
print(A[i])
}
famlearn <- rbindlist(data_list)
tapply(famlearn$Known, famlearn$Subject_nr, sum)
known <- tapply(famlearn$Known, famlearn$Subject_nr, sum)
mean(known)
sum(famlearn$Known)
nrow(famlearn$Known)
18/1890
0.009*100
### Familiarization Interference - Day 3 ####
# How many words were already known to people in Italian
data_list <- list()
for (i in 1:length(A)){
pNumber = A[i]
wd1 <-  paste("//cnas.ru.nl/wrkgrp/STD-Back-Up-Exp2-EEG/", pNumber,"/Day3/", pNumber, "_Familiarization", sep="")
setwd(wd1)
infile1 <- paste(pNumber,"IntFamiliarization.txt",sep="_")
currentFile <- as.data.frame(read.delim(infile1, stringsAsFactors=FALSE, sep = "\t", header = T, skipNul = TRUE))
data_list[[i]] <- currentFile
print(A[i])
}
famint <- rbindlist(data_list)
unknown <- tapply(famint$Known, famint$Subject_nr, sum)
View(famint)
unknown <- tapply(famint$Error, famint$Subject_nr, sum)
unknown
mean(known)
mean(unknown)
unknown <- tapply(famint$Error, by = list(famint$Subject_nr, famint$Condition), sum)
unknown <- tapply(famint$Error, list(famint$Subject_nr, famint$Condition), sum)
unknown
unknown <- as.data.frame(tapply(famint$Error, list(famint$Subject_nr, famint$Condition), sum))
mean(unknown$`1`)
ax(unknown$`1`)
max(unknown$`1`)
sum(unknown$`1`)
nrow(famint[famint$Condition==1,])
945+945
36/945
sd(unknown$`1`)
sd(known)
mean(known)
data_list2 <- list()
for (i in 1:length(A)){
pNumber = A[i]
wd1 <-  paste("//cnas.ru.nl/wrkgrp/STD-Back-Up-Exp2-EEG/", pNumber,"/Day3/", sep="")
setwd(wd1)
infile2 <- paste(pNumber,"GoNogo_logfile.txt",sep="_")
currentFile2 <- as.data.frame(read.cdelim(infile2))
data_list2[[i]] <- currentFile2
}
data_list2 <- list()
for (i in 1:length(A)){
pNumber = A[i]
wd1 <-  paste("//cnas.ru.nl/wrkgrp/STD-Back-Up-Exp2-EEG/", pNumber,"/Day3/", sep="")
setwd(wd1)
infile2 <- paste(pNumber,"GoNogo_logfile.txt",sep="_")
currentFile2 <- read.delim(infile2)
data_list2[[i]] <- currentFile2
}
nogo <- rbindlist(data_list2)
View(nogo)
data_list2 <- list()
for (i in 1:length(A)){
pNumber = A[i]
wd1 <-  paste("//cnas.ru.nl/wrkgrp/STD-Back-Up-Exp2-EEG/", pNumber,"/Day3/", sep="")
setwd(wd1)
infile2 <- paste(pNumber,"GoNogo_logfile.txt",sep="_")
currentFile2 <- read.delim(infile2)
for (j in 1:nrow(currentFile2)){
currentFile2$Subject_nr[j] <- pNumber
}
data_list2[[i]] <- currentFile2
}
nogo <- rbindlist(data_list2)
#### Score calculation NoGo
# Calculate accuracy on go vs nogo trials
nogo_final_error <- data.frame(tapply(nogo$Error, list(nogo$Subject_nr, nogo$Condition), mean, na.rm = T))
nogo_final_error
#### Score calculation NoGo
# Calculate accuracy on go vs nogo trials
nogo_final_error <- data.frame(tapply(nogo$Error, list(nogo$Subject_nr), sum, na.rm = T))
nogo_final_error
#### Score calculation NoGo
# Calculate accuracy on go vs nogo trials
nogo_final_error <- data.frame(table(nogo$Error, list(nogo$Subject_nr), sum, na.rm = T))
#### Score calculation NoGo
# Calculate accuracy on go vs nogo trials
nogo_final_error <- data.frame(table(nogo$Error, nogo$Subject_nr, sum, na.rm = T))
#### Score calculation NoGo
# Calculate accuracy on go vs nogo trials
nogo_final_error <- data.frame(table(nogo$Error, nogo$Subject_nr, na.rm = T))
#### Score calculation NoGo
# Calculate accuracy on go vs nogo trials
nogo_final_error <- table(nogo$Error, nogo$Subject_nr)
nogo_final_error
220+110
table(nogo$SquareType)
table(nogo$SquareType, nogo$Subject_nr)
table(nogo$Condition, nogo$Subject_nr)
214+106
#### Score calculation NoGo
# Calculate accuracy on go vs nogo trials
nogo <- nogo[nogo$BlockNr!=0,]
nogo_final_error <- table(nogo$Error, nogo$Subject_nr)
table(nogo$SquareType, nogo$Subject_nr)
nogo_final_error
# checking the false alarm rate (wrongly pressing in nogo trials)
# define a column that codes for whether a trial was a go or a nogo trial
for (i in 1:nrow(nogo)){
if (nogo$Condition[i] == "o" & nogo$SquareType[i] == "2") {
nogo$trialtype[i] <- "go"}
if (nogo$Condition[i] == "o" & nogo$SquareType[i] == "1") {
nogo$trialtype[i] <- "nogo"}
if (nogo$Condition[i] == "b" & nogo$SquareType[i] == "2") {
nogo$trialtype[i] <- "nogo"}
if (nogo$Condition[i] == "b" & nogo$SquareType[i] == "1") {
nogo$trialtype[i] <- "go"}
}
nogo_final_error[,2]
nogo_final_error[2,]
nogo_final_error[2,] / 104
(nogo_final_error[2,] / 104)*100
FAR <- (nogo_final_error[2,] / 104)*100
mean(FAR)
sd(FAR)
range(FAR)
